{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad60658-5d7d-4829-a365-14b9dfad8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset,Dataset\n",
    "import numpy as np\n",
    "from colorama import Fore\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from Models.Gated_Transformer import Gated_Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a87c2a-211a-4e37-8be1-7381de609204",
   "metadata": {},
   "source": [
    "#### 常数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b168cfe-ddc9-4f4d-ab42-ebd7b2380279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Const(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # 超参数设置\n",
    "        self.epoch=50\n",
    "        self.lr=1e-5\n",
    "        self.device='cuda'\n",
    "        self.batchsize=128\n",
    "        \n",
    "        # 模式选择  \n",
    "        self.nwp= True # True of False\n",
    "        self.type= 'long' # short : 24->4  # long: 96->96 # Custom: 自定义\n",
    "        \n",
    "        # 相关定义\n",
    "        if self.nwp == False:\n",
    "            self.f_in=1\n",
    "        else:\n",
    "            self.f_in=3\n",
    "                   \n",
    "        if self.type=='short':\n",
    "            self.seq_len=24\n",
    "            self.pred_len=4\n",
    "            self.label_len=6\n",
    "        elif self.type=='long':\n",
    "            self.seq_len=96\n",
    "            self.pred_len=96\n",
    "            self.label_len=24           \n",
    "\n",
    "Co=Const()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726c132-4195-416b-be6b-8f9a6d259dbc",
   "metadata": {},
   "source": [
    "#### 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f1a1b4-deb0-4118-acae-e604c6b369ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_customer(Dataset):\n",
    "    def __init__(self,df,size):\n",
    "        # 去除时间列, 修改np 类型 object-->float64\n",
    "        self.data=df.values[:,1:].astype('float64') \n",
    "        self.seq_len = size[0]\n",
    "        self.label_len = size[1]\n",
    "        self.pred_len = size[2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 选取 过去'POWER 作为X1\n",
    "        X1 = self.data[index:index+self.seq_len,0:1]\n",
    "        # 选取 过去'SPEED' 作为X2\n",
    "        X2 = self.data[index:index+self.seq_len,1:2]\n",
    "        # 选取 未来'SPEED' 作为 X3\n",
    "        X3 = self.data[index+self.seq_len:index+self.seq_len+self.pred_len,1:2]\n",
    "        # 选取 POWER 作为 y\n",
    "        y = self.data[index+self.seq_len:index+self.seq_len+self.pred_len,0:1]\n",
    "        return X1,X2,X3,y\n",
    "    def __len__(self):    \n",
    "        return len(self.data) - self.seq_len - self.pred_len + 1\n",
    "# Read and split    \n",
    "df=torch.load('Data/JSFD02/JSFD02')\n",
    "LEN=len(df); \n",
    "train_len=int(LEN*(0.7))\n",
    "valid_len=int(LEN*(0.2))\n",
    "test_len=int(LEN*(0.1))\n",
    "df_train=df.iloc[0:train_len]\n",
    "df_valid=df.iloc[train_len:train_len+valid_len]\n",
    "df_test=df.iloc[-test_len:]\n",
    "size=[Co.seq_len,Co.label_len,Co.pred_len]\n",
    "# Dataset\n",
    "Dataset_train=Dataset_customer(df_train,size)\n",
    "Dataset_valid=Dataset_customer(df_valid,size)\n",
    "Dataset_test=Dataset_customer(df_test,size)\n",
    "Loader_train=DataLoader(Dataset_train,batch_size=Co.batchsize,\n",
    "                        drop_last=True, shuffle=True)\n",
    "Loader_valid=DataLoader(Dataset_valid,batch_size=Co.batchsize,\n",
    "                        drop_last=True, shuffle=True)\n",
    "Loader_test=DataLoader(Dataset_test,batch_size=Co.batchsize,\n",
    "                       drop_last=True, shuffle=True)\n",
    "# [0]: 过去 POWER+SPEED [1]: 未来 SPEED  [2]:未来 POWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd90f07-e3f9-4372-8905-30cb4d368aeb",
   "metadata": {},
   "source": [
    "#### 模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fd1b78-6c3a-4b58-ad30-6900bb71bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    ''' GatedTransformer:\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.Former=Gated_Transformer(num_encoder_layers=1,num_decoder_layers=1,gate=True)\n",
    "        if Co.type=='short':\n",
    "            self.Enc_embed=nn.Conv1d(Co.f_in,128,kernel_size=3,padding=1,dilation=1)\n",
    "        elif Co.type=='long':\n",
    "            self.Enc_embed=net=nn.Sequential(\n",
    "                    nn.Conv1d(Co.f_in,128,kernel_size=3,padding=1,dilation=1),\n",
    "                    nn.Conv1d(128,128,kernel_size=3,padding=2,dilation=2),\n",
    "                    nn.Conv1d(128,128,kernel_size=3,padding=4,dilation=4),\n",
    "                    )\n",
    "        self.Dec_embed=nn.Conv1d(1,128,kernel_size=3,padding=1)\n",
    "        self.Enc_pos=PositionalEmbedding()\n",
    "        self.Dec_pos=PositionalEmbedding()  \n",
    "        self.FC1=nn.Linear(128,1)\n",
    "        self.FC2=nn.Linear(Co.seq_len+Co.label_len,Co.pred_len)  \n",
    "        self.Relu=nn.ReLU()        \n",
    "      \n",
    "    def forward(self,X_enc,X_dec): # [B,X_L,X_F] in, [B,y_L,y_F] out.\n",
    "        X1=self.Enc_embed(X_enc.transpose(1,2)).transpose(1,2)\n",
    "        X2=self.Dec_embed(X_dec.transpose(1,2)).transpose(1,2)\n",
    "        X_enc=X1+self.Enc_pos(X_enc)        \n",
    "        X_dec=X2+self.Dec_pos(X_dec)\n",
    "        out,_=self.Former(X_enc,X_dec) #[B,L,F]-->[B,L,C] 只和X_dec有关\n",
    "        out = self.FC1(out).squeeze(-1)\n",
    "        out = self.FC2(out).unsqueeze(-1)\n",
    "        attns=None\n",
    "        return out,attns\n",
    "    \n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model=128, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2064fc85-b051-499b-97e2-b7afb67838fa",
   "metadata": {},
   "source": [
    "#### 训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b031496-c8fa-4c69-bed6-3b95165dbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XyProcess(X1,X2,X3,y):\n",
    "    # Process\n",
    "    X1=X1.float().to(Co.device); \n",
    "    X2=X2.float().to(Co.device); \n",
    "    X3=X3.float().to(Co.device)\n",
    "    y=y.float().to(Co.device)\n",
    "    # Reconstruct\n",
    "    if Co.nwp == True:\n",
    "        X3=torch.cat([X2,X3],dim=1)[:,-Co.seq_len:,:]\n",
    "        X=torch.cat([X1,X2,X3],dim=-1)\n",
    "    else:\n",
    "        X=X1\n",
    "    X_enc=X\n",
    "    X_dec1 = X1[:,-Co.label_len:,:]\n",
    "    X_dec2 = torch.zeros_like(X1).float().to(Co.device)\n",
    "    X_dec = torch.cat([X_dec1,X_dec2],dim=1)\n",
    "    return X_enc,X_dec,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5bb853-505c-4d74-b52f-d3312bd6c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Valid():\n",
    "    global best_valid_loss\n",
    "    model.eval()\n",
    "    LOSS=[]\n",
    "    for X1,X2,X3,y in Loader_valid:\n",
    "        #--------------\n",
    "        X_enc,X_dec,y=XyProcess(X1,X2,X3,y)\n",
    "        #--------------\n",
    "        out,attns=model(X_enc,X_dec)\n",
    "        loss=crt(out,y)\n",
    "        #-------------\n",
    "        LOSS.append(loss.item())\n",
    "    LOSS=np.mean(LOSS)\n",
    "    t2=time.time()\n",
    "    print(f'valid_loss={LOSS:.4f},time={t2-t1:.2f}s/epoch')\n",
    "    if LOSS<best_valid_loss:\n",
    "        best_valid_loss=LOSS\n",
    "        print(Fore.GREEN+f'best_valid_loss={best_valid_loss:.4f}'+Fore.RESET)\n",
    "        torch.save(model,path_model)\n",
    "        metric['valid_loss'][ITER]=LOSS\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ea72e6-1e2a-422c-8037-4258445dcd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test():\n",
    "    model=torch.load(path_model)\n",
    "    model.eval()\n",
    "    crt1=nn.MSELoss()\n",
    "    crt2=nn.L1Loss() # MAE\n",
    "    LOSS1=[]; LOSS2=[];\n",
    "    for X1,X2,X3,y in Loader_test:\n",
    "        #--------------\n",
    "        X_enc,X_dec,y=XyProcess(X1,X2,X3,y)\n",
    "        #--------------\n",
    "        out,attns=model(X_enc,X_dec)\n",
    "        loss1=crt1(out,y)\n",
    "        loss2=crt2(out,y)\n",
    "        #-------------\n",
    "        LOSS1.append(loss1.item())\n",
    "        LOSS2.append(loss2.item())\n",
    "    LOSS1=np.mean(LOSS1)\n",
    "    LOSS2=np.mean(LOSS2)\n",
    "    print(Fore.RED+f'test_MSEloss={LOSS1:.4f}'+Fore.RESET) \n",
    "    metric['test_loss']['MSE'][ITER]=LOSS1\n",
    "    metric['test_loss']['MAE'][ITER]=LOSS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd124b7-e903-41a7-8b0c-7ad6d3ecaa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric={'valid_loss':torch.empty(5,1),\n",
    "        'test_loss':  {'MSE':torch.empty(5,1),\n",
    "                       'MAE':torch.empty(5,1) }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bde8fc7-316a-4579-a9e0-192f7bf18966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================  ITER = 0  ====================\n",
      "epoch=0,train_loss=0.9045,valid_loss=0.9482,time=7.21s/epoch\n",
      "\u001b[32mbest_valid_loss=0.9482\u001b[39m\n",
      "epoch=1,train_loss=0.7236,valid_loss=0.7783,time=5.57s/epoch\n",
      "\u001b[32mbest_valid_loss=0.7783\u001b[39m\n",
      "epoch=2,train_loss=0.6185,valid_loss=0.7134,time=5.59s/epoch\n",
      "\u001b[32mbest_valid_loss=0.7134\u001b[39m\n",
      "epoch=3,train_loss=0.5751,valid_loss=0.6802,time=5.58s/epoch\n",
      "\u001b[32mbest_valid_loss=0.6802\u001b[39m\n",
      "epoch=4,train_loss=0.5487,valid_loss=0.6500,time=5.57s/epoch\n",
      "\u001b[32mbest_valid_loss=0.6500\u001b[39m\n",
      "epoch=5,train_loss=0.5181,valid_loss=0.5999,time=6.02s/epoch\n",
      "\u001b[32mbest_valid_loss=0.5999\u001b[39m\n",
      "epoch=6,train_loss=0.4775,valid_loss=0.5448,time=6.25s/epoch\n",
      "\u001b[32mbest_valid_loss=0.5448\u001b[39m\n",
      "epoch=7,train_loss=0.4412,valid_loss=0.4975,time=6.38s/epoch\n",
      "\u001b[32mbest_valid_loss=0.4975\u001b[39m\n",
      "epoch=8,train_loss=0.4121,valid_loss=0.4644,time=6.43s/epoch\n",
      "\u001b[32mbest_valid_loss=0.4644\u001b[39m\n",
      "epoch=9,train_loss=0.3861,valid_loss=0.4407,time=6.12s/epoch\n",
      "\u001b[32mbest_valid_loss=0.4407\u001b[39m\n",
      "epoch=10,train_loss=0.3636,valid_loss=0.4200,time=6.32s/epoch\n",
      "\u001b[32mbest_valid_loss=0.4200\u001b[39m\n",
      "epoch=11,train_loss=0.3458,valid_loss=0.4008,time=6.26s/epoch\n",
      "\u001b[32mbest_valid_loss=0.4008\u001b[39m\n",
      "epoch=12,train_loss=0.3330,valid_loss=0.3909,time=6.16s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3909\u001b[39m\n",
      "epoch=13,train_loss=0.3236,valid_loss=0.3855,time=6.32s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3855\u001b[39m\n",
      "epoch=14,train_loss=0.3165,valid_loss=0.3765,time=6.15s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3765\u001b[39m\n",
      "epoch=15,train_loss=0.3105,valid_loss=0.3772,time=6.40s/epoch\n",
      "epoch=16,train_loss=0.3050,valid_loss=0.3685,time=6.22s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3685\u001b[39m\n",
      "epoch=17,train_loss=0.3000,valid_loss=0.3667,time=5.97s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3667\u001b[39m\n",
      "epoch=18,train_loss=0.2951,valid_loss=0.3527,time=6.02s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3527\u001b[39m\n",
      "epoch=19,train_loss=0.2903,valid_loss=0.3479,time=6.08s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3479\u001b[39m\n",
      "epoch=20,train_loss=0.2857,valid_loss=0.3497,time=6.15s/epoch\n",
      "epoch=21,train_loss=0.2817,valid_loss=0.3425,time=5.92s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3425\u001b[39m\n",
      "epoch=22,train_loss=0.2778,valid_loss=0.3365,time=5.93s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3365\u001b[39m\n",
      "epoch=23,train_loss=0.2742,valid_loss=0.3313,time=5.97s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3313\u001b[39m\n",
      "epoch=24,train_loss=0.2708,valid_loss=0.3329,time=6.00s/epoch\n",
      "epoch=25,train_loss=0.2678,valid_loss=0.3278,time=6.32s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3278\u001b[39m\n",
      "epoch=26,train_loss=0.2648,valid_loss=0.3303,time=6.03s/epoch\n",
      "epoch=27,train_loss=0.2624,valid_loss=0.3261,time=6.24s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3261\u001b[39m\n",
      "epoch=28,train_loss=0.2596,valid_loss=0.3286,time=6.27s/epoch\n",
      "epoch=29,train_loss=0.2572,valid_loss=0.3125,time=6.16s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3125\u001b[39m\n",
      "epoch=30,train_loss=0.2547,valid_loss=0.3227,time=6.38s/epoch\n",
      "epoch=31,train_loss=0.2522,valid_loss=0.3142,time=6.37s/epoch\n",
      "epoch=32,train_loss=0.2498,valid_loss=0.3119,time=6.37s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3119\u001b[39m\n",
      "epoch=33,train_loss=0.2475,valid_loss=0.3064,time=6.29s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3064\u001b[39m\n",
      "epoch=34,train_loss=0.2451,valid_loss=0.3115,time=6.17s/epoch\n",
      "epoch=35,train_loss=0.2429,valid_loss=0.3150,time=6.26s/epoch\n",
      "epoch=36,train_loss=0.2408,valid_loss=0.3115,time=6.41s/epoch\n",
      "epoch=37,train_loss=0.2386,valid_loss=0.3066,time=6.41s/epoch\n",
      "epoch=38,train_loss=0.2362,valid_loss=0.3101,time=6.22s/epoch\n",
      "epoch=39,train_loss=0.2343,valid_loss=0.3070,time=6.29s/epoch\n",
      "epoch=40,train_loss=0.2323,valid_loss=0.3032,time=6.34s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3032\u001b[39m\n",
      "epoch=41,train_loss=0.2306,valid_loss=0.3026,time=6.13s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3026\u001b[39m\n",
      "epoch=42,train_loss=0.2285,valid_loss=0.3016,time=6.32s/epoch\n",
      "\u001b[32mbest_valid_loss=0.3016\u001b[39m\n",
      "epoch=43,train_loss=0.2265,valid_loss=0.3062,time=6.05s/epoch\n",
      "epoch=44,train_loss=0.2249,valid_loss=0.2998,time=6.33s/epoch\n",
      "\u001b[32mbest_valid_loss=0.2998\u001b[39m\n",
      "epoch=45,train_loss=0.2231,valid_loss=0.2953,time=6.27s/epoch\n",
      "\u001b[32mbest_valid_loss=0.2953\u001b[39m\n",
      "epoch=46,train_loss=0.2215,valid_loss=0.2968,time=6.16s/epoch\n",
      "epoch=47,train_loss=0.2199,valid_loss=0.3025,time=6.02s/epoch\n",
      "epoch=48,train_loss=0.2185,valid_loss=0.3008,time=6.37s/epoch\n",
      "epoch=49,train_loss=0.2170,valid_loss=0.3089,time=6.35s/epoch\n",
      "\u001b[31mtest_MSEloss=0.4728\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "for ITER in range(1): #大循环5次，取平均值\n",
    "    print('='*20+f'  ITER = {ITER}  '+'='*20)\n",
    "    path_model=f'Checkpt/G_Former/G_Former_[NWP={Co.nwp}][Type={Co.type}][Iter={ITER}].pt'\n",
    "    path_metric=f'Checkpt/G_Former/metric[NWP={Co.nwp}][Type={Co.type}].pt'\n",
    "    model=Model().to(Co.device)\n",
    "    opt=torch.optim.Adam(model.parameters(),lr=Co.lr)\n",
    "    crt=nn.MSELoss()\n",
    "    best_valid_loss=float('inf')\n",
    "    for epoch in range(50):\n",
    "        LOSS=[]\n",
    "        t1=time.time()\n",
    "        for X1,X2,X3,y in Loader_train:\n",
    "            #--------------\n",
    "            X_enc,X_dec,y=XyProcess(X1,X2,X3,y)\n",
    "            #--------------\n",
    "            opt.zero_grad()\n",
    "            out,attns=model(X_enc,X_dec)\n",
    "            loss=crt(out,y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            #-------------\n",
    "            LOSS.append(loss.item())\n",
    "        LOSS=np.mean(LOSS)\n",
    "        print(f'epoch={epoch},train_loss={LOSS:.4f},',end='')\n",
    "        Valid()\n",
    "    Test()\n",
    "torch.save(metric,path_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802ad78-294e-4cc6-96c4-e216ae6331b2",
   "metadata": {},
   "source": [
    "#### Metric输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd6b9a0-520c-45e2-a8db-c167fe69fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWP is [True], Type is [long]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(f'NWP is [{Co.nwp}], Type is [{Co.type}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8e336e1-8944-4a0e-a8fd-6f0d3d012a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE平均值为2421525711834064219013120.0000,误差为+9686102847336256876052480.0000,-2421525711834064219013120.0000\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "MSE_mean=torch.mean(metric['test_loss']['MSE'])\n",
    "MSE_1=max(metric['test_loss']['MSE'])-MSE_mean\n",
    "MSE_2=MSE_mean-min(metric['test_loss']['MSE'])\n",
    "print(f'MSE平均值为{MSE_mean:.4f},误差为+{MSE_1.item():.4f},-{MSE_2.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5d42a3-9b89-4b92-aa55-49c8962501a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE平均值为-3835157584519221925704282144768.0000,误差为+3835157584519221925704282144768.0000,-15340630338076887702817128579072.0000\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "MAE_mean=torch.mean(metric['test_loss']['MAE'])\n",
    "MAE_1=max(metric['test_loss']['MAE'])-MAE_mean\n",
    "MAE_2=MAE_mean-min(metric['test_loss']['MAE'])\n",
    "print(f'MAE平均值为{MAE_mean:.4f},误差为+{MAE_1.item():.4f},-{MAE_2.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd235fdc-4b52-4c30-bcb5-e1d00509ecb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d70e0-534c-42da-8440-16786b0b0cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
